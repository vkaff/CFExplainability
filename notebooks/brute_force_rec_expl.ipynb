{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import scipy.stats as st\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['../spotlight_ext']:\n",
    "    module_path = os.path.abspath(os.path.join(p))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "models_path = '../models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "\n",
    "# get dataset\n",
    "dataset = get_movielens_dataset(variant='1M')\n",
    "train, test = random_train_test_split(dataset)\n",
    "\n",
    "train = train.to_sequence()\n",
    "test = test.to_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "ofile = 'entire_model_1m.pt'\n",
    "model = torch.load(os.path.join(models_path, ofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize input parameters\n",
    "k = 10\n",
    "no_interactions = 10\n",
    "total_CFs = 1\n",
    "max_interacted_items_to_del = 4\n",
    "user_id = 8\n",
    "\n",
    "proximity_weight, diversity_weight = 1, 0\n",
    "\n",
    "FLOAT_MAX = np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yloss(curr_score, kth_score):\n",
    "    yloss = 0.0\n",
    "    for i in range(total_CFs):\n",
    "        temp_loss = curr_score/kth_score\n",
    "\n",
    "        yloss += temp_loss    \n",
    "\n",
    "    return yloss/total_CFs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(x_hat, x1):\n",
    "    \"\"\"Compute weighted distance between two vectors.\"\"\"\n",
    "#     return sum(abs(x_hat - x1))\n",
    "    diff = set(x1).difference(set(x_hat))\n",
    "    return len(diff)\n",
    "\n",
    "def compute_proximity_loss(cfs, x1):\n",
    "    proximity_loss = 0.0\n",
    "    for i in range(total_CFs):        \n",
    "        proximity_loss += compute_dist(cfs[i], x1)\n",
    "    return proximity_loss/total_CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diversity_loss():\n",
    "    proximity_loss = 0.0\n",
    "    return proximity_loss/total_CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss():\n",
    "    \"\"\"Computes the overall loss\"\"\"\n",
    "    yloss = compute_yloss()\n",
    "    proximity_loss = compute_proximity_loss() if proximity_weight > 0 else 0.0\n",
    "    diversity_loss = compute_diversity_loss() if diversity_weight > 0 else 0.0    \n",
    "\n",
    "    loss = yloss + (proximity_weight * proximity_loss) - (diversity_weight * diversity_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemInteractionInfo:\n",
    "    user_id = -1\n",
    "    item_id = -1\n",
    "    score = 0\n",
    "    pos = -1\n",
    "    interactions = []\n",
    "    complete_interactions = []\n",
    "    recommends = []\n",
    "    iter_no = -1\n",
    "    satisfy_objective = True\n",
    "    satisfy_contraints = True\n",
    "    y_loss = FLOAT_MAX\n",
    "    proximity_loss = FLOAT_MAX\n",
    "    \n",
    "    def __init__(self, uid, iid=-1, p=-1, i=None):\n",
    "        self.user_id = uid\n",
    "        self.item_id = iid\n",
    "        self.pos = p\n",
    "        self.interactions = i\n",
    "        \n",
    "    def __str__(self): \n",
    "        sorted_recommended_items = [(n[0], n[1].detach().numpy().flatten()[0]) if isinstance(n[1], torch.Tensor) else (n[0], n[1]) for n in self.recommends]\n",
    "            \n",
    "        return (f'\\n'\n",
    "                f'user_id: {self.user_id}, item_id: {self.item_id}\\n'\n",
    "                f'yloss: {round(self.y_loss, 4)}, proximity_loss: {int(self.proximity_loss)}\\n'\n",
    "                f'Item {self.item_id} is in position {self.pos} now!!!\\n'\n",
    "                f'Found in iteration {self.iter_no} and the interacted items are {self.interactions}\\n'\n",
    "                f'10-best recommended items {sorted_recommended_items}\\n')\n",
    "    \n",
    "    def set_flags(self, do_objective, do_contraints):\n",
    "        satisfy_objective = do_objective\n",
    "        satisfy_contraints = do_contraints\n",
    "    \n",
    "    def needs_update(self, loss):\n",
    "        is_better = [False, False]\n",
    "        if len(loss):\n",
    "            if self.satisfy_objective:\n",
    "                if self.proximity_loss > loss['proximity']:\n",
    "                    is_better[1] = True\n",
    "            else: is_better[1] = True\n",
    "            \n",
    "            if self.satisfy_contraints:\n",
    "                if loss['yloss'] < 1.0:\n",
    "                    is_better[0] = True\n",
    "            else: is_better[0] = True\n",
    "                \n",
    "            if all(is_better):\n",
    "                return True\n",
    "        \n",
    "        return False    \n",
    "    \n",
    "    def set_values(self, predictions, interacted_items, tot_interacted_items, loss, iter_no, k=10):\n",
    "        # get the ranking position of selected item in the list\n",
    "        self.pos = st.rankdata(-predictions, method='ordinal')[self.item_id]\n",
    "        self.recommends = sorted(enumerate(predictions), key=lambda x: x[1], reverse=True)[:k]\n",
    "        self.iter_no = iter_no\n",
    "        self.y_loss = loss[0]\n",
    "        self.proximity_loss = loss[1]\n",
    "        self.interactions = interacted_items\n",
    "        self.complete_interactions = tot_interacted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following interactions [446 508 447 488 472 514 437 493 512 444] for user 8, the top-10 recommended items are [482, 473, 582, 1439, 641, 686, 28, 1360, 1369, 499]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select item (position) to exclude from recommended list:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected item in pos 7 is 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_interacted = test.sequences[test.user_ids==user_id][0]\n",
    "predictions = -model.predict(items_interacted[:min(no_interactions, len(items_interacted))])\n",
    "predictions[items_interacted] = FLOAT_MAX\n",
    "\n",
    "print(f'Given the following interactions {items_interacted[:no_interactions]} for user {user_id}, the top-{k} recommended items are '\n",
    "      f'{list(predictions.argsort()[:k])}')\n",
    "cand_pos = input('Select item (position) to exclude from recommended list: ')\n",
    "try:\n",
    "    cand = predictions.argsort()[min(k, int(cand_pos)) - 1]\n",
    "except ValueError:\n",
    "    print(\"That's not an int!\")\n",
    "\n",
    "kth_item = predictions.argsort()[k - 1]\n",
    "\n",
    "print(f'The selected item in pos {cand_pos} is {cand}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with 1 interacted items removed...\n",
      "Checking with 2 interacted items removed...\n",
      "Checking with 3 interacted items removed...\n",
      "Checking with 4 interacted items removed...\n",
      "\n",
      "Best total loss\n",
      " =============== \n",
      "user_id: 8, item_id: 28\n",
      "yloss: 0.9468, proximity_loss: 1\n",
      "Item 28 is in position 12 now!!!\n",
      "Found in iteration 3 and the interacted items are (446, 508, 447, 488, 472, 514, 437, 512, 444)\n",
      "10-best recommended items [(482, 0.0068613114), (512, 0.0048286864), (1439, 0.0048122746), (473, 0.0047043166), (582, 0.004634982), (686, 0.0045875977), (905, 0.0036776608), (1369, 0.003592616), (485, 0.0034962047), (641, 0.0034026843)]\n",
      "Similarities of removed items:  [9.]\n",
      "\n",
      "Best yloss\n",
      " ========== \n",
      "user_id: 8, item_id: 28\n",
      "yloss: 0.9855, proximity_loss: 4\n",
      "Item 28 is in position 33 now!!!\n",
      "Found in iteration 357 and the interacted items are (508, 514, 437, 493, 512, 444)\n",
      "10-best recommended items [(686, 0.0072493297), (466, 0.0063285567), (1439, 0.006167974), (485, 0.006009351), (482, 0.005336869), (905, 0.0051946524), (483, 0.004589856), (582, 0.004585693), (462, 0.004552886), (519, 0.0044093)]\n",
      "Similarities of removed items:  [7. 5. 1. 4.]\n",
      "\n",
      "Total iterations: 386\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, combinations\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "counter = 1\n",
    "best_total_loss = ItemInteractionInfo(user_id, cand)\n",
    "best_yloss = ItemInteractionInfo(user_id, cand)\n",
    "best_yloss.satisfy_objective = False\n",
    "\n",
    "for l in range(1, min(max_interacted_items_to_del, len(items_interacted)) + 1):\n",
    "    print(f'Checking with {l} interacted items removed...')\n",
    "#     produce permutations of various interactions\n",
    "    perm = combinations(items_interacted[:min(no_interactions, len(items_interacted))], min(no_interactions, len(items_interacted)) - l)    \n",
    "\n",
    "    for i in perm:\n",
    "#         predict next top-k items about to be selected        \n",
    "        preds = model.predict(i) \n",
    "#     convert logits produced by model, i.e., the probability distribution before normalization, by using softmax\n",
    "        tensor = torch.from_numpy(preds).float()\n",
    "        preds = F.softmax(tensor, dim=0)\n",
    "        \n",
    "        yloss = compute_yloss(preds.numpy()[cand], preds.numpy()[kth_item])\n",
    "        proximity_loss = compute_proximity_loss(np.asarray(i)[np.newaxis, :], items_interacted)    \n",
    "#     keep info about the best solution found depending on an objective function\n",
    "        if best_total_loss.needs_update(dict(yloss=yloss, proximity=proximity_loss)):\n",
    "            best_total_loss.set_values(preds, i, [yloss, proximity_loss], counter, k)\n",
    "        if best_yloss.needs_update(dict(yloss=yloss, proximity=proximity_loss)):\n",
    "            best_yloss.set_values(preds, i, [yloss, proximity_loss], counter, k) \n",
    "\n",
    "        counter += 1\n",
    "\n",
    "similarity_rank = k - st.rankdata(similarity_matrix[cand, items_interacted]) + 1\n",
    "\n",
    "print('\\nBest total loss\\n', '=' * len('Best total loss'), best_total_loss)\n",
    "idx_items_exluded = np.where(np.isin(items_interacted, list(set(items_interacted).difference(set(best_total_loss.interactions)))))\n",
    "print('Similarities of removed items: ', similarity_rank[idx_items_exluded])\n",
    "\n",
    "print('\\nBest yloss\\n', '=' * len('Best yloss'), best_yloss)\n",
    "idx_items_exluded = np.where(np.isin(items_interacted, list(set(items_interacted).difference(set(best_yloss.interactions)))))\n",
    "print('Similarities of removed items: ', similarity_rank[idx_items_exluded])\n",
    "\n",
    "print(f'\\nTotal iterations: {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized technique using item-similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the item-item similarity matrix\n",
    "\n",
    "# construct \n",
    "M = np.zeros((dataset.num_users, dataset.num_items))\n",
    "for u in range(1, dataset.num_users):    \n",
    "    np.add.at(M[u], dataset.item_ids[dataset.user_ids==u], dataset.ratings[dataset.user_ids==u])\n",
    "\n",
    "M_u = M.mean(axis=1)\n",
    "item_mean_subtracted = M - M_u[:, np.newaxis]\n",
    "similarity_matrix = 1 - squareform(pdist(item_mean_subtracted.T, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for user 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19\n",
      "Process ended\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, combinations\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "max_interacted_items_to_del = 4\n",
    "k = 10\n",
    "cand_pos = 7\n",
    "\n",
    "best_tot_loss_data = []\n",
    "best_yloss_data = []\n",
    "users_no_data = []\n",
    "\n",
    "print(f'Checking for user', end='')\n",
    "delimiter = ''\n",
    "for user_id in range(1, 20):  # dataset.num_users):\n",
    "    print(f'{delimiter} {user_id}', end='')\n",
    "    delimiter = ','\n",
    "    \n",
    "    best_total_loss = ItemInteractionInfo(user_id)\n",
    "    best_yloss = ItemInteractionInfo(user_id)\n",
    "    best_yloss.satisfy_objective = False\n",
    "    \n",
    "    try:\n",
    "        if all(v > 0 for v in test.sequences[test.user_ids==user_id][0]):\n",
    "            items_interacted = test.sequences[test.user_ids==user_id][0]\n",
    "            predictions = -model.predict(items_interacted)\n",
    "            predictions[items_interacted] = FLOAT_MAX\n",
    "            kth_item = predictions.argsort()[k - 1]\n",
    "            rec_item_exclude = predictions.argsort()[min(k, int(cand_pos)) - 1]\n",
    "            \n",
    "            best_total_loss.item_id = rec_item_exclude\n",
    "            best_yloss.item_id = rec_item_exclude\n",
    "\n",
    "            counter = 1        \n",
    "\n",
    "            for l in range(1, min(max_interacted_items_to_del, len(items_interacted)) + 1):            \n",
    "            #     produce permutations of various interactions\n",
    "                perm = combinations(items_interacted, len(items_interacted) - l)    \n",
    "\n",
    "                for i in perm:\n",
    "            #         predict next top-k items about to be selected        \n",
    "                    preds = model.predict(i) \n",
    "            #     convert logits produced by model, i.e., the probability distribution before normalization, by using softmax\n",
    "                    tensor = torch.from_numpy(preds).float()\n",
    "                    preds = F.softmax(tensor, dim=0)\n",
    "\n",
    "                    yloss = compute_yloss(preds.numpy()[rec_item_exclude], preds.numpy()[kth_item])\n",
    "                    proximity_loss = compute_proximity_loss(np.asarray(i)[np.newaxis, :], items_interacted)    \n",
    "            #     keep info about the best solution found depending on an objective function\n",
    "                    if best_total_loss.needs_update(dict(yloss=yloss, proximity=proximity_loss)):\n",
    "                        best_total_loss.set_values(preds, i, items_interacted, [yloss, proximity_loss], counter, k)\n",
    "                    if best_yloss.needs_update(dict(yloss=yloss, proximity=proximity_loss)):\n",
    "                        best_yloss.set_values(preds, i, items_interacted, [yloss, proximity_loss], counter, k)                 \n",
    "\n",
    "                    counter += 1\n",
    "    except IndexError as err:        \n",
    "        users_no_data.append(user_id)\n",
    "        \n",
    "    best_tot_loss_data.append(best_total_loss)\n",
    "    best_yloss_data.append(best_yloss)\n",
    "\n",
    "print('\\nProcess ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "total_data = []\n",
    "for rec in best_tot_loss_data:\n",
    "    if rec.item_id == -1: continue\n",
    "    \n",
    "    similarity_rank = k - st.rankdata(similarity_matrix[rec.item_id, rec.complete_interactions]) + 1\n",
    "    del_items_indices = np.where(np.isin(rec.complete_interactions, list(set(rec.complete_interactions).difference(set(rec.interactions)))))\n",
    "    total_data.extend(list(similarity_rank[del_items_indices].astype(int)))\n",
    "    \n",
    "cnt = Counter(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 1., 2., 1., 5., 4., 1., 4., 1., 1.]),\n",
       " array([ 1. ,  1.9,  2.8,  3.7,  4.6,  5.5,  6.4,  7.3,  8.2,  9.1, 10. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with matplotlib\n",
    "plt.hist(list(cnt.keys()), weights=list(cnt.values()), width=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFExplainability",
   "language": "python",
   "name": "cfexplainability"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
